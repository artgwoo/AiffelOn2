{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f4cbd6",
   "metadata": {},
   "source": [
    "# 프로젝트: 단어 Level로 번역기 업그레이드하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5b0e3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd4b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import re    \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a1ca1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수: 217975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119518</th>\n",
       "      <td>Are you a high school student?</td>\n",
       "      <td>Es-tu lycéen ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36181</th>\n",
       "      <td>We spoke in French.</td>\n",
       "      <td>Nous avons parlé en français.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113793</th>\n",
       "      <td>I know a good French teacher.</td>\n",
       "      <td>Je connais un bon professeur de français.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40855</th>\n",
       "      <td>It's a little dated.</td>\n",
       "      <td>C'est un peu désuet.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23003</th>\n",
       "      <td>Tom worked there.</td>\n",
       "      <td>Tom y travaillait.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   eng  \\\n",
       "119518  Are you a high school student?   \n",
       "36181              We spoke in French.   \n",
       "113793   I know a good French teacher.   \n",
       "40855             It's a little dated.   \n",
       "23003                Tom worked there.   \n",
       "\n",
       "                                              fra  \\\n",
       "119518                             Es-tu lycéen ?   \n",
       "36181               Nous avons parlé en français.   \n",
       "113793  Je connais un bon professeur de français.   \n",
       "40855                        C'est un peu désuet.   \n",
       "23003                          Tom y travaillait.   \n",
       "\n",
       "                                                       cc  \n",
       "119518  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "36181   CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "113793  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "40855   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "23003   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수:', len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f508d095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67209</th>\n",
       "      <td>What do you do for fun?</td>\n",
       "      <td>Que faites-vous pour vous amuser ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67192</th>\n",
       "      <td>What did they bring me?</td>\n",
       "      <td>Que m'ont-ils apporté ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83342</th>\n",
       "      <td>Tom says you're a genius.</td>\n",
       "      <td>Tom dit que vous êtes un génie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91722</th>\n",
       "      <td>This is an important step.</td>\n",
       "      <td>C'est une étape importante.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74564</th>\n",
       "      <td>Tom is insanely jealous.</td>\n",
       "      <td>Tom est maladivement jaloux.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              eng                                 fra\n",
       "67209     What do you do for fun?  Que faites-vous pour vous amuser ?\n",
       "67192     What did they bring me?             Que m'ont-ils apporté ?\n",
       "83342   Tom says you're a genius.     Tom dit que vous êtes un génie.\n",
       "91722  This is an important step.         C'est une étape importante.\n",
       "74564    Tom is insanely jealous.        Tom est maladivement jaloux."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][60000:93000]\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6463b49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['You were there, right?', 'You will stay at home.',\n",
       "       \"You won't be punished.\", ..., 'What time did you wake up?',\n",
       "       'What time did you wake up?', 'What time did you wake up?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_np_eng= lines['eng'].to_numpy()\n",
    "lines_np_fra= lines['fra'].to_numpy()\n",
    "lines_np_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae46bcb5",
   "metadata": {},
   "source": [
    "실습에서 구현한 번역기는 글자 단위(Character-level)에서 구현된 번역기였습니다. 하지만 실제 번역기의 경우에는 글자 단위가 아니라 단어 단위(Word-level)에서 구현되는 것이 좀 더 보편적입니다.\n",
    "\n",
    "동일한 데이터셋을 사용하면서 글자 단위와는 다른 전처리와 to_categorical() 함수가 아닌 임베딩 층(Embedding layer)를 추가하여 단어 단위의 번역기를 완성시켜보겠습니다. 하지만, 단어 단위로 할 경우에는 단어의 개수가 글자 단위로 했을 경우와 비교하여 단어장의 크기(Vocabulary) 크기도 커지고, 학습 속도도 좀 더 느려집니다. 학습과 테스트 시의 원활한 진행을 위해서 데이터에서 상위 33,000개의 샘플만 사용해주세요.\n",
    "\n",
    "33000개 중 3000개는 테스트 데이터로 분리하여 모델을 학습한 후에 번역을 테스트 하는 용도로 사용합니다.\n",
    "\n",
    "# Step 1. 정제, 정규화, 전처리 (영어, 프랑스어 모두!)\n",
    "\n",
    "글자 단위가 아닌 단어 단위의 번역기를 하기 위해서는 글자 단위에서는 신경쓰지 않았던 몇 가지 추가적인 전처리가 필요합니다.\n",
    "\n",
    "## 1. 구두점(Punctuation)을 단어와 분리해주세요.\n",
    "\n",
    "일반적으로 영어권 언어의 경우에는 띄어쓰기 단위로 단어를 분리합니다. 토큰화(Tokenization) 라고도 불리는 이 작업은 어디서부터 어디까지가 하나의 단어인지를 구분하는 작업인데요, 그런데 띄어쓰기를 해주기 전에 구두점을 분리하는 작업이 필요할 때가 있습니다.\n",
    "\n",
    "예를 들어서 'he is a good boy!'라는 문장이 있을 때, 이를 띄어쓰기 단위로 토큰화한다면 ['he', 'is', 'a', 'good', 'boy!']가 됩니다. 그런데 실제로 !는 boy와 붙어있는 한 단어가 아니므로 좀 더 올바른 전처리는 ['he', 'is', 'a', 'good', 'boy', '!']가 맞습니다.\n",
    "!나 ? 또는 온점과 같은 특수문자들을 구두점(punctuation)이라고 부릅니다. 이들을 토큰화하기 전에 단어와 미리 분리시켜주세요!\n",
    "\n",
    "- 분리 전 : he is a Good boy!\n",
    "- 분리 후 : he is a Good boy !\n",
    "\n",
    "\n",
    "\n",
    "## 2. 소문자로 바꿔주세요.\n",
    "\n",
    "기계가 보기에는 스펠링이 같더라도 대문자로 된 단어와 소문자로 된 단어는 서로 다른 단어입니다. 예를 들어 'Good'과 'good'은 기계가 보기에는 다른 단어입니다. 그래서 모든 문장에 대해서 전부 영어로 바꿔주는 작업을 하겠습니다.\n",
    "\n",
    "- 변환 전 : he is a Good boy !\n",
    "- 변환 후 : he is a good boy !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "097986fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = '<start> '\n",
    "eos_token = ' <end>'\n",
    "\n",
    "def preprocess_line(line, plus_token = True):\n",
    "    # 소문자로 변경하기\n",
    "    line = line.lower().strip()\n",
    "    # 구두점(Punctuation)을 단어와 분리하기\n",
    "    line = re.sub(r\"([?.!,¿])\", r\" \\1 \", line)\n",
    "    line = re.sub(r'[\" \"]+', \" \", line)\n",
    "    line = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", line)\n",
    "\n",
    "    line = line.strip()\n",
    "    \n",
    "    if plus_token == True:\n",
    "        line = sos_token + line + eos_token\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600823b",
   "metadata": {},
   "source": [
    "## 3. 띄어쓰기 단위로 토큰화를 수행하세요.\n",
    "띄어쓰기 단위로 토큰화를 수행해서 단어를 분리하는 작업을 해주세요. 기계는 이렇게 분리된 토큰들을 각각 하나의 단어로 인식할 수 있게 됩니다.\n",
    "\n",
    "- 토큰화 전 : 'he is a good boy !'\n",
    "- 토큰화 후 : ['he', 'is', 'a', 'good', 'boy', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf7b8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer(\n",
    "        num_words=7000,  \n",
    "        filters=' ',   \n",
    "        oov_token=\"<unk>\"  \n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)  \n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2542beb",
   "metadata": {},
   "source": [
    "## 영어, 프랑스어 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "462d2bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_lines = []\n",
    "fra_lines = []\n",
    "\n",
    "# eng_lines.append(lines.eng.apply(lambda x : preprocess_line(x,plus_token = False)))\n",
    "# fra_lines.append(lines.fra.apply(lambda x : preprocess_line(x),))\n",
    "\n",
    "for eng, fra in zip(lines.eng, lines.fra):\n",
    "    if len(eng) == 0: continue\n",
    "    if len(fra) == 0: continue   \n",
    "        \n",
    "    eng_lines.append(preprocess_line(eng, plus_token = False))\n",
    "    fra_lines.append(preprocess_line(fra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ec1a475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(eng_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8211a319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 15, 105, 23, 374, 34, 19, 7, 22, 8, 6, 3],\n",
       " [2, 15, 3036, 151, 78, 4, 3],\n",
       " [2, 15, 13, 1135, 8, 3723, 4, 3],\n",
       " [2, 10, 19, 347, 8, 16, 1519, 4, 3],\n",
       " [2, 15, 13, 389, 8, 16, 1519, 4, 3],\n",
       " [2, 10, 19, 1647, 8, 17, 4, 3],\n",
       " [2, 15, 443, 176, 9, 5098, 4, 3],\n",
       " [2, 15, 443, 176, 9, 35, 20, 128, 278, 4, 3],\n",
       " [2, 15, 443, 176, 9, 26, 841, 72, 4, 3],\n",
       " [2, 10, 1136, 176, 9, 10, 841, 72, 4, 3]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tensor, eng_tokenizer = tokenize(eng_lines)\n",
    "fra_tensor, fra_tokenizer = tokenize(fra_lines)\n",
    "fra_tensor[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46febdf8",
   "metadata": {},
   "source": [
    "## input, target 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01c25d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = eng_tensor\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[char for char in line if char != fra_tokenizer.word_index['<end>']] for line in fra_tensor]\n",
    "# 시작 토큰 제거\n",
    "decoder_target =[[char for char in line if char != fra_tokenizer.word_index['<start>']] for line in fra_tensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a92ef03",
   "metadata": {},
   "source": [
    "# padding 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50da85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(tensor):\n",
    "    total_data_text = list(tensor)\n",
    "    num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "    max_tokens = max(num_tokens)\n",
    "#     max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "    maxlen = int(max_tokens)\n",
    "    tensor = pad_sequences(tensor, padding='post', maxlen=maxlen)  \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "255e9b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 10)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 17)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 17)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_tensor(encoder_input)\n",
    "decoder_input = pad_tensor(decoder_input)\n",
    "decoder_target = pad_tensor(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f8a752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index)+1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index)+1\n",
    "\n",
    "max_eng_seq_len = encoder_input.shape[1]\n",
    "max_fra_seq_len = decoder_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2f7139d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 5795\n",
      "프랑스어 단어장의 크기 : 8297\n",
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 17\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645aac06",
   "metadata": {},
   "source": [
    "## train, test dataset 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f273db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b8b81a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 10)\n",
      "(30000, 17)\n",
      "(30000, 17)\n",
      "(3000, 10)\n",
      "(3000, 17)\n",
      "(3000, 17)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ac247",
   "metadata": {},
   "source": [
    "# Step 2. 디코더의 문장에 시작 토큰과 종료 토큰을 넣어주세요.\n",
    "\n",
    "글자 단위 번역기를 구현할 때와 마찬가지로 디코더의 입력 시퀀스 맨 앞에는 시작을 의미하는 토큰인 <sos>가 필요합니다. 그리고 교사 강요를 수행할 때, 디코더의 실제값이 되는 디코더의 레이블 시퀀스에는 종료를 의미하는 종료 토큰 <eos>가 필요합니다.\n",
    "예를 들어 번역 문장이 \"Courez!\" 였다고 한다면, Step 1을 거친 후에는 다음과 같은 결과를 얻습니다.\n",
    "\n",
    "- Step 1을 수행한 후 : ['courez', '!']\n",
    "    \n",
    "이 문장에 대해서 각각 디코더의 입력 시퀀스와 레이블 시퀀스를 만들면 다음과 같습니다.\n",
    "\n",
    "- 입력 시퀀스 : ['<sos>', 'courez', '!']\n",
    "- 레이블 시퀀스 : ['courez', '!', '<eos>']\n",
    "    \n",
    "참고로 Step 2가 반드시 Step 1이 끝난 후에 이루어질 필요는 없습니다!\n",
    "Step 1을 수행하는 중간에 수행해도 상관없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318f7c8",
   "metadata": {},
   "source": [
    "## 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd28351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 512\n",
    "hidden_size = 512\n",
    "# 인코더에서 사용할 임베딩 층 사용 예시\n",
    "encoder_inputs = Input(shape=(None, ), name='encoder_input')\n",
    "enc_emb =  Embedding(eng_vocab_size, embedding_size,\n",
    "                    input_length=max_eng_seq_len)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_size, dropout = 0.5, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7248d22",
   "metadata": {},
   "source": [
    "## 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "396de905",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, ), name='decoder_input')\n",
    "dec_emb =  Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(hidden_size, dropout = 0.5, return_sequences = True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c19be44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12184b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52d22651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 512)    2967040     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 512)    4248064     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 512)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 512)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 512), (None, 2099200     masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 512),  2099200     masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8297)   4256361     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 15,669,865\n",
      "Trainable params: 15,669,865\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5aa146e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 29s 21ms/step - loss: 1.9273 - val_loss: 1.5904\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4627 - val_loss: 1.3739\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 1.2704 - val_loss: 1.2469\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.1413 - val_loss: 1.1616\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.0423 - val_loss: 1.0992\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.9618 - val_loss: 1.0575\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.8959 - val_loss: 1.0246\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.8439 - val_loss: 1.0119\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.8073 - val_loss: 1.0060\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.7754 - val_loss: 0.9956\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.7444 - val_loss: 0.9866\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.7225 - val_loss: 0.9890\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.7078 - val_loss: 0.9891\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6848 - val_loss: 0.9746\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6649 - val_loss: 0.9832\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6556 - val_loss: 0.9921\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.6487 - val_loss: 0.9927\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6406 - val_loss: 0.9891\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6267 - val_loss: 0.9911\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6215 - val_loss: 0.9898\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6130 - val_loss: 0.9867\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6034 - val_loss: 0.9885\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5975 - val_loss: 0.9839\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5900 - val_loss: 0.9858\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5825 - val_loss: 0.9868\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5805 - val_loss: 0.9879\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5752 - val_loss: 0.9818\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5692 - val_loss: 0.9815\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5613 - val_loss: 0.9792\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5550 - val_loss: 0.9758\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5493 - val_loss: 0.9733\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5433 - val_loss: 0.9708\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5379 - val_loss: 0.9725\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5329 - val_loss: 0.9696\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5278 - val_loss: 0.9683\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5245 - val_loss: 0.9706\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5209 - val_loss: 0.9675\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5156 - val_loss: 0.9653\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5133 - val_loss: 0.9633\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5088 - val_loss: 0.9656\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5045 - val_loss: 0.9631\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5007 - val_loss: 0.9642\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4988 - val_loss: 0.9617\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4965 - val_loss: 0.9598\n",
      "Epoch 45/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4945 - val_loss: 0.9611\n",
      "Epoch 46/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4919 - val_loss: 0.9634\n",
      "Epoch 47/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4898 - val_loss: 0.9614\n",
      "Epoch 48/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4880 - val_loss: 0.9645\n",
      "Epoch 49/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4853 - val_loss: 0.9647\n",
      "Epoch 50/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4841 - val_loss: 0.9628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efdf3d5a5e0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], \n",
    "          y=decoder_target_train, \n",
    "          validation_data = ([encoder_input_test, decoder_input_test], \n",
    "                             decoder_target_test),\n",
    "          batch_size=32, \n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c76336b",
   "metadata": {},
   "source": [
    "# Step 3. 케라스의 토크나이저로 텍스트를 숫자로 바꿔보세요.\n",
    "\n",
    "딥러닝 모델은 텍스트가 아닌 숫자를 처리합니다. 케라스 토크나이저를 사용해서 각 단어를 고유한 정수로 바꿔보세요.\n",
    "케라스 토크나이저의 사용법은 아래의 링크에서 2. 케라스(Keras)의 텍스트 전처리에 설명되어 있습니다.\n",
    "\n",
    "- 위키독스\n",
    "\n",
    "위 링크의 가이드를 통해서 영어와 프랑스어에 대한 토크나이저를 각각 생성하고, tokenizer.texts_to_sequences()를 사용하여 모든 샘플에 대해서 정수 시퀀스로 변환해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d752e",
   "metadata": {},
   "source": [
    "## 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d7069a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 512)         2967040   \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 512), (None, 512) 2099200   \n",
      "=================================================================\n",
      "Total params: 5,066,240\n",
      "Trainable params: 5,066,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c024c",
   "metadata": {},
   "source": [
    "## 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e175b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(embedding_size,))\n",
    "decoder_state_input_c = Input(shape=(embedding_size,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "026410a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93974ba",
   "metadata": {},
   "source": [
    "# Step 4. 임베딩 층(Embedding layer) 사용하기\n",
    "이번에는 입력이 되는 각 단어를 임베딩 층을 사용하여 벡터화하겠습니다.\n",
    "임베딩 층을 사용하는 방법과 그 설명에 대해서는 아래의 링크의 1. 케라스 임베딩 층(Keras Embedding layer) 을 참고하세요.\n",
    "\n",
    "위키독스\n",
    "실제 번역기 구현을 위해서 사용할 수 있는 인코더 코드의 예시는 다음과 같습니다. 이를 통해서 인코더와 디코더의 임베딩 층을 각각 구현해보세요.\n",
    "\n",
    "> from tensorflow.keras.layers import Input, Embedding, Masking    \n",
    "#인코더에서 사용할 임베딩 층 사용 예시     \n",
    "encoder_inputs = Input(shape=(None,))     \n",
    "enc_emb =  Embedding(단어장의 크기, 임베딩 벡터의 차원)(encoder_inputs)     \n",
    "encoder_lstm = LSTM(hidden state의 크기, return_state=True)    \n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)    \n",
    "\n",
    "주의할 점은 인코더와 디코더의 임베딩 층은 서로 다른 임베딩 층을 사용해야 하지만, 디코더의 훈련 과정과 테스트 과정(예측 과정)에서의 임베딩 층은 동일해야 한다는 것입니다!\n",
    "\n",
    "\n",
    "# Step 5. 모델 구현하기\n",
    "글자 단위 번역기에서 구현한 모델을 참고로 단어 단위 번역기의 모델을 완성시켜보세요! 이때는 label이 integer 값이므로 categorical entropy loss가 아닌 sparse categorical entropy loss를 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13e76311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 512)    4248064     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 512),  2099200     embedding_2[0][0]                \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8297)   4256361     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,603,625\n",
      "Trainable params: 10,603,625\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2] + decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62207272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <start>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = fra2idx['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76a98f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + idx2eng[i]+' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e48a09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=fra2idx['<start>']) and i!=fra2idx['<end>']):\n",
    "            temp = temp + idx2fra[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430bb7e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36382a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e93ebcc9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60d8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfd9fe12",
   "metadata": {},
   "source": [
    "# Step 6. 모델 평가하기\n",
    "\n",
    "단어 단위 번역기를 이용하여 훈련 데이터의 샘플과 테스트 데이터의 샘플로 번역 문장을 만들어보고 정답 문장과 번역 문장을 비교해보세요. 이전 스텝들에서 우리가 공부했던 모델의 경우 글자 단위에서 구현된 번역기이며 현재 프로젝트를 진행할 때 사용하는 모델은 단어 단위에서 구현되는 번역기입니다.\n",
    "\n",
    ">Embedding layer가 추가되기 때문에 학습했던 내용 그대로 사용할 경우 shape에서 error가 발생합니다.    \n",
    "decode sentence를 구성할 때 고민해보세요!!\n",
    "\n",
    "고민하다 풀리지 않을 경우에는 하단 내용 참고해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eeb2ddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: i know where tom lives . \n",
      "정답 문장: je sais o vit tom . \n",
      "번역기가 번역한 문장:  je sais o tom to\n",
      "-----------------------------------\n",
      "입력 문장: i lost a bunch of keys . \n",
      "정답 문장: j ai gar un trousseau de cl s . \n",
      "번역기가 번역한 문장:  je me ne de de d\n",
      "-----------------------------------\n",
      "입력 문장: the weather was beautiful . \n",
      "정답 문장: le temps tait magnifique . \n",
      "번역기가 번역한 문장:  le temps temps d\n",
      "-----------------------------------\n",
      "입력 문장: uranus is full of methane . \n",
      "정답 문장: <unk> est pleine de m <unk> . \n",
      "번역기가 번역한 문장:  la est la du des \n",
      "-----------------------------------\n",
      "입력 문장: did you sign a contract ? \n",
      "정답 문장: avez vous sign un contrat ? \n",
      "번역기가 번역한 문장:  avez vous vous u\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [1,201,501,1004,2015]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', seq2src(encoder_input_test[seq_index]))\n",
    "    print('정답 문장:', seq2tar(decoder_input_test[seq_index]))\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe576f67",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56c68683",
   "metadata": {},
   "source": [
    "### 회고\n",
    "코드에 대한 이해가 모두 되진 않지만 이곳 저곳을 참고해서 결과가 나오긴 했다.\n",
    "구글번역과 비교하니 얼추 비슷하게 변역이 되어서 다행이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f602f4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
